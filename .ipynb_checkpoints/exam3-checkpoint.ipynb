{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b1d10258555fda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Question 1: What are voting classifiers in ensemble learning?\n",
    "\n",
    "A voting classifier is an ensemble learning method designed to bring together the predictions of several different machine learning models to arrive at a final classification decision. This method is commonly used to solve classification problems in which each model votes on which category the sample belongs to. Below is a detailed explanation of voting classifiers:\n",
    "\n",
    "1. __Hard Voting__:\n",
    "Hard Voting is a form of voting classifier in which multiple models select the final prediction according to Majority Vote. In Hard Voting, each model makes a prediction for a given input sample, and then the final prediction is the category that receives the most votes.\n",
    "__EXAMPLE__: Suppose there are three different models A, B, and C that each classify the same sample. Model A predicts category 1, model B predicts category 2, and model C predicts category 1. Since category 1 received two votes and category 2 only one vote, the final decision in hard voting is to choose category 1.\n",
    "__Hard voting is applicable to both binary classification problems and multi-category classification problems.__ It is a simple but effective method that is often used to combine several different types of models to obtain more stable and accurate classification results.\n",
    "\n",
    "2. __Soft Voting__:\n",
    "Unlike hard voting, soft voting takes into account the predicted probability or score of each model, not just the category labels. In soft voting, each model estimates a probability or score for each category for a given input sample and the final decision is based on the average of these probabilities.\n",
    "__EXAMPLE__: Suppose there are three different models A, B, and C that classify the same sample. Model A estimates the probability of the sample belonging to category 1 to be 0.7 and category 2 to be 0.3; model B estimates the probability of category 1 to be 0.4 and category 2 to be 0.6; and model C estimates the probability of category 1 to be 0.6 and category 2 to be 0.4. In soft voting the probabilities of each category are averaged, and the final decision is then likely to be on category 1 because it has the highest average probability.\n",
    "__Soft voting is commonly used to deal with probability estimation and is particularly suitable for multi-category classification problems__ because it is able to utilise probabilistic information from multiple models.\n",
    "\n",
    "__Advantages of voting classifiers include:__\n",
    "- Improved model robustness, as it combines the opinions of multiple models.\n",
    "- Reduces the variance of the model, especially when a single model may overfit the data.\n",
    "- Allows combining different types of models for better performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2: Explain the role of the regularization parameter C in a Support Vector Machine (SVM) model. How does varying C affect the model’s bias and variance trade-off?\n",
    "\n",
    "In Support Vector Machines (SVMs), the regularisation parameter C is a key hyperparameter that is used to control the complexity and tolerance of the model. The role of C is to balance the trade-off between maximising intervals and minimising classification errors. This balance affects the performance of the SVM model on both training and unseen data.\n",
    "\n",
    "The following is the role and impact of the regularisation parameter C:\n",
    "\n",
    "__Role of C:__\n",
    "C controls the tolerance of the SVM model during training. Smaller values of C encourage greater spacing of the model, i.e., some training samples are allowed to be misclassified in order to maintain the simplicity of the model.\n",
    "Larger values of C cause the model to adapt more tightly to the training data to minimise classification errors, i.e. reduce the spacing, which can lead to more complex decision boundaries.\n",
    "\n",
    "__Affects the bias and variance trade-off of the model:__\n",
    "\n",
    "- __Small C (larger intervals, high bias, low variance):__\n",
    "    - A smaller C value will result in a larger interval for the model, allowing some training samples to be misclassified.\n",
    "    - This will lead to high bias because the model is more concerned with classifying the training data correctly rather than striving for a smaller training error.\n",
    "    - Models with high bias may be oversimplified and insensitive to noise in the data, and therefore may perform better on unseen data.\n",
    "\n",
    "- __Large C (smaller interval, low bias, high variance):__\n",
    "    - A larger C value will result in the model adapting more tightly to the training data to minimise classification errors.\n",
    "    - This will result in low bias as the model is more concerned with classifying the training data correctly, i.e., it seeks a smaller training error.\n",
    "    - Models with low bias may be more complex and sensitive to noise in the training data and therefore may overfit and perform poorly on unseen data.\n",
    "\n",
    "Thus, the choice of C affects the bias and variance trade-off of the SVM model. __Smaller C values produce high bias, low variance models for noisier data, while larger C values produce low bias, high variance models for cleaner data.__ Choosing the appropriate C-value is key, and methods such as cross-validation are often required to determine the optimal hyper-parameter settings that will allow the model to perform well on both training and test data.\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3: Follow the 7-steps to model building for your selected ticker.\n",
    "\n",
    "### 步骤一：数据收集和预处理\n",
    "调用tushare的sdk抓取600073这支股票从2010-01-01到2022-12-31这六年时间内的日行情数据，包括交易日期、开盘价、最高价、最低价、收盘价、昨收价、涨跌额、涨跌幅、成交量、成交额"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c00c3e5528da26",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ts_code trade_date   open   high    low  close  pre_close  change  \\\n",
      "0     600073.SH   20211231   7.95   8.13   7.94   8.09       7.97    0.12   \n",
      "1     600073.SH   20211230   7.92   7.99   7.92   7.97       7.94    0.03   \n",
      "2     600073.SH   20211229   8.01   8.05   7.93   7.94       8.03   -0.09   \n",
      "3     600073.SH   20211228   8.07   8.09   8.00   8.03       8.07   -0.04   \n",
      "4     600073.SH   20211227   7.99   8.07   7.96   8.07       7.99    0.08   \n",
      "...         ...        ...    ...    ...    ...    ...        ...     ...   \n",
      "2820  600073.SH   20100108  10.20  10.44  10.18  10.44      10.28    0.16   \n",
      "2821  600073.SH   20100107  10.58  10.65  10.25  10.28      10.65   -0.37   \n",
      "2822  600073.SH   20100106  10.83  10.89  10.64  10.65      10.84   -0.19   \n",
      "2823  600073.SH   20100105  10.72  10.88  10.60  10.84      10.75    0.09   \n",
      "2824  600073.SH   20100104  10.56  10.94  10.56  10.75      10.57    0.18   \n",
      "\n",
      "      pct_chg        vol      amount  \n",
      "0      1.5056  150337.07  121128.014  \n",
      "1      0.3778   64586.06   51445.668  \n",
      "2     -1.1208   90722.45   72347.819  \n",
      "3     -0.4957   88413.60   70987.108  \n",
      "4      1.0013  123911.38   99343.914  \n",
      "...       ...        ...         ...  \n",
      "2820   1.5600   38885.69   40172.364  \n",
      "2821  -3.4700   62913.55   65521.521  \n",
      "2822  -1.7500   60507.14   65094.784  \n",
      "2823   0.8400   64429.53   69369.576  \n",
      "2824   1.7000   86862.58   93618.762  \n",
      "\n",
      "[2825 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "\n",
    "ts.set_token('7cb6ebc6b67bc4757d18b217c149110ad8f2654766fef3b0a18828ee')\n",
    "pro = ts.pro_api()\n",
    "# 上海梅林 600073.SH\n",
    "df = pro.daily(ts_code='600073.SH', start_date='2010-01-01', end_date='2022-12-31')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f630bb695b43c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 步骤二：特征工程\n",
    "### 步骤三：数据标记\n",
    "### 步骤四：数据拆分\n",
    "### 步骤五：模型选择和构建\n",
    "### 步骤六：超参数调优\n",
    "### 步骤七：模型评估"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
